#colnames(PEF_dates_meta)
#colnames(PEF_Scans_meta)
#
PEF_dates_meta %>% dplyr::group_by(`GPS Time`) %>% tally()
PEF_Scans_meta %>% dplyr::group_by(`GPS Time`) %>% tally()
PEF_dates_meta %>%
#anti_join(PEF_Scans_meta, by=c("taxon_code","scan_num","Latitude","Longitude")) %>%
anti_join(PEF_Scans_meta, by=c("File Name")) %>% dim
library(spectrolab)
library(tidyverse)
library(Polychrome)
library(gplots)
library(OpenImageR)
source("./Functions/Scan_Metadata_Reader.R")
####################
path = "Original_data/Field_spec/Maine/PEF_scans_06182019/"
PEF_06182019_spectra <- read_spectra(paste(path), format="sed")
PEF_06182019_files <- read_files(path)
PEF_06182019_names <- scan_names(PEF_06182019_files)
PEF_06182019_batch <- read_batch(PEF_06182019_files)
# combine into metadata
PEF_06182019_meta <- cbind(PEF_06182019_names, PEF_06182019_batch) %>% as.data.frame()
rownames(PEF_06182019_meta) <- NULL
# set metadata
meta(PEF_06182019_spectra) = data.frame(PEF_06182019_meta, stringsAsFactors = FALSE)
path = "Original_data/Field_spec/Maine/PEF_scans_06192019/"
PEF_06192019_spectra <- read_spectra(paste(path), format="sed")
PEF_06192019_files <- read_files(path)
PEF_06192019_names <- scan_names(PEF_06192019_files)
PEF_06192019_batch <- read_batch(PEF_06192019_files)
# combine into metadata
PEF_06192019_meta <- cbind(PEF_06192019_names, PEF_06192019_batch) %>% as.data.frame()
rownames(PEF_06192019_meta) <- NULL
# set metadata
meta(PEF_06192019_spectra) = data.frame(PEF_06192019_meta, stringsAsFactors = FALSE)
####################
path = "Original_data/Field_spec/Maine/PEF_scans_07082019/"
PEF_07082019_spectra <- read_spectra(paste(path), format="sed")
PEF_07082019_files <- read_files(path)
PEF_07082019_names <- scan_names(PEF_07082019_files)
PEF_07082019_batch <- read_batch(PEF_07082019_files)
View(read_batch)
files <- PEF_07082019_files
files_batch<-lapply(files,read_header)
files_batch<-lapply(files,read_header, show_col_types = F)
read_delim(paste(path,files[1],sep=""), n_max=24, delim=":"
read_header<-function(files) {read_delim(paste(path,files[1],sep=""), n_max=24, delim=":") %>%
as.data.frame() %>%
dplyr::select(2)}
read_delim(paste(path,files[1],sep=""), n_max=24, delim=":") %>%
as.data.frame() %>%
dplyr::select(2)}
read_delim(paste(path,files[1],sep=""), n_max=24, delim=":") %>%
as.data.frame() %>%
dplyr::select(2)
files_batch<-lapply(files,read_header) %>% spec(show_col_types = FALSE)
files_batch<-lapply(files,read_header)
options(readr.show_types = FALSE)
files_batch<-lapply(files,read_header)
options(readr.show_col_types = FALSE)
files_batch<-lapply(files,read_header)
files_batch<-files_batch %>% as.data.frame() %>% t
#Make a list of header names
files_cols<-lapply(files, read_header_cols) %>% as.data.frame()
##Make header names the column names
colnames(files_batch)<-files_cols[,1]
return(files_batch)
files_batch
PEF_07082019_batch <- read_batch(PEF_07082019_files)
# combine into metadata
PEF_07082019_meta <- cbind(PEF_07082019_names, PEF_07082019_batch) %>% as.data.frame()
rownames(PEF_07082019_meta) <- NULL
# set metadata
meta(PEF_07082019_spectra) = data.frame(PEF_07082019_meta, stringsAsFactors = FALSE)
####################
path = "Original_data/Field_spec/Maine/PEF_Scans/"
PEF_spectra <- read_spectra(paste(path), format="sed")
PEF_Scans_files <- read_files(path)
PEF_Scans_names <- scan_names(PEF_Scans_files)
PEF_Scans_batch <- read_batch(PEF_Scans_files)
# combine into metadata
PEF_Scans_meta <- cbind(PEF_Scans_names, PEF_Scans_batch) %>% as.data.frame()
rownames(PEF_Scans_meta) <- NULL
# set metadata
meta(PEF_spectra) = data.frame(PEF_Scans_meta, stringsAsFactors = FALSE)
##############
# combine spectra
tst <- c(PEF_07082019_spectra, PEF_06182019_spectra, PEF_06192019_spectra)
tst < -spectrolab::combine(PEF_07082019_spectra, PEF_06182019_spectra)
tst <- spectrolab::combine(PEF_07082019_spectra, PEF_06182019_spectra)
PEF_dates_spectra <- spectrolab::combine(tst, PEF_07082019_spectra)
# import file path names of .rds files into character list (spectral libraries based on each location in Alaska)
tst_list <- list.files("./Outputs", pattern=".rds", full.names = T)
# reads in the spectral libraries for each location in a list...list of 13 spectral objects
tst_list_of_SpecLib <- lapply(tst_list, readRDS)%>% # reads in the spectral library for each site
setNames(gsub("Output/", "", tst_list)) # removes dir path from the name
PEF_dates_spectra <- Reduce(spectrolab::combine, tst_list_of_SpecLib)
tst_list_of_SpecLib
tst_list
PEF_dates_spectra <- Reduce(spectrolab::combine, tst_list_of_SpecLib)
# reads in the spectral libraries for each location in a list...list of 13 spectral objects
tst_list_of_SpecLib <- lapply(tst_list, readRDS)%>% # reads in the spectral library for each site
setNames(gsub("Output/", "", tst_list)) # removes dir path from the name
tst_list_of_SpecLib
lapply(tst_list, readRDS)
tst_list
# import file path names of .rds files into character list (spectral libraries based on each location in Alaska)
tst_list <- list.files("Outputs", pattern=".rds", full.names = T)
tst_list
# reads in the spectral libraries for each location in a list...list of 13 spectral objects
tst_list_of_SpecLib <- lapply(tst_list, readRDS) %>% # reads in the spectral library for each site
setNames(gsub("Output/", "", tst_list)) # removes dir path from the name
tst_list_of_SpecLib
lapply(tst_list, readRDS)
##############
# check to see if the separate PEF folders have the same scans as the full PEF folder
PEF_dates_meta <- rbind(PEF_06192019_meta, PEF_06182019_meta, PEF_07082019_meta) %>% as.data.frame()
#colnames(PEF_dates_meta)
#colnames(PEF_Scans_meta)
PEF_dates_meta %>% dplyr::group_by(`GPS Time`) %>% tally()
PEF_Scans_meta %>% dplyr::group_by(`GPS Time`) %>% tally()
PEF_dates_meta %>%
#anti_join(PEF_Scans_meta, by=c("taxon_code","scan_num","Latitude","Longitude")) %>%
anti_join(PEF_Scans_meta, by=c("File Name")) %>% dim
source("Functions/Scan_Metadata_Reader.R")
################
path = "Original_data/Field_Spec/Maine/HOW_scans_07042019/"
HOW_07042019_spectra <- read_spectra(paste(path), format="sed")
HOW_07042019_files <- read_files(path)
HOW_07042019_names <- scan_names(HOW_07042019_files)
HOW_07042019_batch <- read_batch(HOW_07042019_files)
# combine into metadata
HOW_07042019_meta <- cbind(HOW_07042019_names, HOW_07042019_batch) %>% as.data.frame()
rownames(HOW_07042019_meta) <- NULL
# set metadata
meta(HOW_07042019_spectra) = data.frame(HOW_07042019_meta, stringsAsFactors = FALSE)
################
path = "Original_data/Field_Spec/Maine/HOW_scans_07092019/"
HOW_07092019_spectra <- read_spectra(paste(path), format="sed")
HOW_07092019_files <- read_files(path)
HOW_07092019_names <- scan_names(HOW_07092019_files)
HOW_07092019_batch <- read_batch(HOW_07092019_files)
# combine into metadata
HOW_07092019_meta <- cbind(HOW_07092019_names, HOW_07092019_batch) %>% as.data.frame()
rownames(HOW_07092019_meta) <- NULL
# set metadata
meta(HOW_07092019_spectra) = data.frame(HOW_07092019_meta, stringsAsFactors = FALSE)
##############
#Combine spectra
HOW_dates_spectra <- spectrolab::combine(HOW_07042019_spectra, HOW_07092019_spectra)
##############
# read in data as spectra
path = "Original_data/Field_spec/Maine/Howland_Scans/"
HOW_Scans_spectra <- read_spectra(paste(path), format="sed")
HOW_Scans_files <- read_files(path)
HOW_Scans_names <- scan_names(HOW_Scans_files)
HOW_Scans_batch <- read_batch(HOW_Scans_files)
# combine into metadata
HOW_Scans_meta <- cbind(HOW_Scans_names, HOW_Scans_batch) %>% as.data.frame()
rownames(HOW_Scans_meta) <- NULL
# set metadata
meta(HOW_Scans_spectra) = data.frame(HOW_Scans_meta, stringsAsFactors = FALSE)
##############
##Check to see if the separate PEF folders have the same scans as the full PEF folder
HOW_dates_meta <- rbind(HOW_07042019_meta, HOW_07092019_meta) %>% as.data.frame()
HOW_dates_meta %>%
anti_join(HOW_Scans_meta, by=c("File Name")) %>% dim
source("Functions/Scan_Metadata_Reader.R")
## Combine spectral libraries
TreeSpecLib <- spectrolab::combine(PEF_dates_spectra,HOW_dates_spectra) %>%
as.data.frame()
TreeSpecLib_df <- TreeSpecLib %>%
as.data.frame()
View(TreeSpecLib)
TreeSpecLib_df <- TreeSpecLib_df %>%
dplyr::filter(duplicated(TreeSpecLib_df[,32:ncol(SpecLib_df)]) == FALSE) #%>%
## Combine spectral libraries
TreeSpecLib <- spectrolab::combine(PEF_dates_spectra,HOW_dates_spectra)
TreeSpecLib_df <- TreeSpecLib %>%
as.data.frame()
TreeSpecLib_df <- TreeSpecLib_df %>%
dplyr::filter(duplicated(TreeSpecLib_df[,32:ncol(TreeSpecLib_df)]) == FALSE) #%>%
View(TreeSpecLib_df)
TreeSpecLib_unique <- as_spectra(TreeSpecLib_df[-1:-31])
meta(TreeSpecLib_unique) = TreeSpecLib_df[c(1:31)] %>% as.data.frame()
colnames(TreeSpecLib_df)
Target_names <- unique(sort(SpecLib_df$taxon_code))
Target_names <- unique(sort(TreeSpecLib_df$taxon_code))
Target_names
# Creates an empty list
each_target <- list()
# function splits the spectral library into spectral objects based on each target (105 Spectral Objects)
for(i in 1:length(Target_names)){
# subset a functional group
each_target[[i]] <- subset(SpecLib_df, taxon_code == Target_names[i])
# saves metadata
metadata <- each_target[[i]][,c(1:31)] %>%
as.data.frame()
# convert to a spectral object
each_target[[i]] <- as_spectra(each_target[[i]][-1:-31])
# add metadata
meta(each_target[[i]]) <- data.frame(metadata[,c(1:31)], stringsAsFactors = FALSE)
}
# subset a functional group
each_target[[i]] <- subset(TreeSpecLib_df, taxon_code == Target_names[i])
# function splits the spectral library into spectral objects based on each target (105 Spectral Objects)
for(i in 1:length(Target_names)){
# subset a functional group
each_target[[i]] <- subset(TreeSpecLib_df, taxon_code == Target_names[i])
# saves metadata
metadata <- each_target[[i]][,c(1:31)] %>%
as.data.frame()
# convert to a spectral object
each_target[[i]] <- as_spectra(each_target[[i]][-1:-31])
# add metadata
meta(each_target[[i]]) <- data.frame(metadata[,c(1:31)], stringsAsFactors = FALSE)
}
# Renames each target in list
each_target <- each_target %>%
setNames(Target_names)
each_target
View(TreeSpecLib_df)
#[1] "abibal" "acepen" "acerub" "alninc" "betall" "betpap" "betpop"
#[8] "faggra" "fraame" "larlar" "picrub" "pinstr" "popgra" "prupen"
#[15] "querub" "rhutyp" "tsucan"
#plot_interactive(each_target[["abibal"    ]]) #
each_target[["abibal"]] <- each_target[["abibal"]][-c(11, 12, 48), ]
#plot_interactive(each_target[["acepen"    ]]) # Good
#plot_interactive(each_target[["acerub"    ]]) #
each_target[["acerub"]] <- each_target[["acerub"]][-c(3,21, 22, 25, 27), ]
each_target[["acerub"]] <- each_target[["acerub"]][-c(15:19), ]
each_target[["acerub"]] <- each_target[["acerub"]][-c(19), ]
#plot_interactive(each_target[["betall"    ]]) #
each_target[["betall"]] <- each_target[["betall"]][-c(10), ]
#plot_interactive(each_target[["faggra"    ]]) # Good mostly
each_target[["faggra"]] <- each_target[["faggra"]][-c(17, 18), ]
#plot_interactive(each_target[["picrub"    ]]) # Good mostly
each_target[["picrub"]] <- each_target[["picrub"]][-c(27,33), ]
View(each_target)
#plot_interactive(each_target[["querub"    ]]) # Good mostly
#plot_interactive(each_target[["rhutyp"    ]]) # Good mostly
each_target[["rhutyp"]] <- each_target[["rhutyp"]][-c(10, 13, 20, 21), ]
#plot_interactive(each_target[["tsucan"    ]]) # Good mostly
each_target[["tsucan"]] <- each_target[["tsucan"]][-c(37,38), ]
each_target[["tsucan"]] <- each_target[["tsucan"]][-c(20), ]
each_target[["tsucan"]] <- each_target[["tsucan"]][-c(17), ]
# Creates a new object with cleaned spectral library
New_targets <- each_target
# combines all species into one spectral library if satisfied with our results
# the result is a dataframe
Cleaned_TreeSpeclib <- Reduce(spectrolab::combine, New_targets) %>%
as.data.frame() #%>% # Converts Spectral Object to a dataframe
# Creates .rds object
Cleaned_TreeSpeclib_rds <- Reduce(spectrolab::combine, New_targets)
View(Cleaned_TreeSpeclib)
# function splits the spectral library into spectral objects based on each target (105 Spectral Objects)
for(i in 1:length(Target_names)){
# subset a functional group
each_target[[i]] <- subset(TreeSpecLib_df, taxon_code == Target_names[i])
# saves metadata
metadata <- each_target[[i]][,c(1:31)] %>%
as.data.frame()
# convert to a spectral object
each_target[[i]] <- as_spectra(each_target[[i]][-1:-31])
# add metadata
meta(each_target[[i]]) <- data.frame(metadata[ ,c(1:31)], stringsAsFactors = FALSE)
}
library(spectrolab)
library(tidyverse)
library(raster)
library(SpaDES)
library(doParallel)
library(parallel)
library(hsdar)
library(caret)
library(ranger)
library(tools)
library(randomForest)
##Make spectral derivatives
###Run LandCoverEstimator to generate Spectral Derivatives.
#source("Functions/LandCoverEstimator.R")
#source("Functions/1_LCE_derivs.R")
source("Functions/2_LCE_veg_index.R")
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
View(Deriv_combine)
View(Deriv_combine)
##Make spectral derivatives
###Run LandCoverEstimator to generate Spectral Derivatives.
#source("Functions/LandCoverEstimator.R")
#source("Functions/1_LCE_derivs.R")
source("Functions/2_LCE_veg_index.R")
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
##Make spectral derivatives
###Run LandCoverEstimator to generate Spectral Derivatives.
#source("Functions/LandCoverEstimator.R")
source("Functions/1_LCE_derivs.R")
source("Functions/2_LCE_veg_index.R")
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
##Make spectral derivatives
###Run LandCoverEstimator to generate Spectral Derivatives.
#source("Functions/LandCoverEstimator.R")
source("Functions/1_LCE_derivs.R")
source("Functions/2_LCE_veg_index.R")
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
View(Func_Resamp)
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
filename = "Outputs/Cleaned_Tree_SpectralLib.csv"
# reads in spectral library as .csv
# right now your spectral library would have already have weird values removed/replaced
Spectral_lib <- read.csv(filename, check.names = F)
View(Spectral_lib)
Spectral_lib <- Deriv_combine(Spectral_lib)
x = Spectral_lib
# resampling datas et
Resampled_data <- Func_Resamp(x)
# calculating VIs for data set
VegIndex_data <- Func_VI(x)
# Removes metadata before function can be applied
df<-metaRemove(x)
# Converts the dataframe to a spectral object
SpeclibObj<-spectrolab::as_spectra(df)
print("Resampling spectra every 5nm")
# Creates functions that will do the resampling every 5nm
final <- spectrolab::resample(SpeclibObj, seq(397.593, 899.424, 5)) %>%
as.data.frame() %>%
dplyr::select(-sample_name)
# rename columns
colnames(final) <- paste(colnames(final), "5nm", sep = "_")
# Combines all the dataframes created into one df
ResampledDF <- cbind(bandsRemove(Resamp), final)
# Combines all the dataframes created into one df
ResampledDF <- cbind(bandsRemove(x), final)
print("Resampling sucessful")
ResampledDF
Resampled_data <- ResampledDF
# calculating VIs for data set
VegIndex_data <- Func_VI(x)
DF <- cbind(VegIndex_data, metaRemove(Resampled_data))
View(DF)
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
##Make spectral derivatives
###Run LandCoverEstimator to generate Spectral Derivatives.
#source("Functions/LandCoverEstimator.R")
#source("Functions/1_LCE_derivs.R")
source("Functions/2_LCE_veg_index.R")
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
##Make spectral derivatives
###Run LandCoverEstimator to generate Spectral Derivatives.
#source("Functions/LandCoverEstimator.R")
#source("Functions/1_LCE_derivs.R")
source("Functions/2_LCE_veg_index.R")
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
##Make spectral derivatives
###Run LandCoverEstimator to generate Spectral Derivatives.
#source("Functions/LandCoverEstimator.R")
#source("Functions/1_LCE_derivs.R")
#source("Functions/2_LCE_veg_index.R")
source("Functions/tree_veg_index.R")
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
detach("package:raster", unload = TRUE)
detach("package:caret", unload = TRUE)
detach("package:ranger", unload = TRUE)
detach("package:tools", unload = TRUE)
library(tools)
detach("package:tools", unload = TRUE)
library(tools)
detach("package:randomForest", unload = TRUE)
require(spectrolab)
require(tidyverse)
#library(raster)
#library(SpaDES)
require(doParallel)
require(parallel)
require(hsdar)
# make spectral derivatives
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
# read functions
source("Functions/tree_veg_index.R")
# make spectral derivatives
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
# read functions
source("Functions/tree_veg_index.R")
# make spectral derivatives
Make_Speclib_Derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
# read functions
source("Functions/tree_veg_index.R")
# make spectral derivatives
make_speclib_derivs("Outputs/Cleaned_Tree_SpectralLib.csv", out_file = "Outputs/")
# Spectral Library
TreeSpecLib_derivs <- read.csv("Outputs/D_002_SpecLib_Derivs.csv")
colnames(TreeSpecLib_derivs) %>% View()
colnames(TreeSpecLib_derivs) %>% View()
colnames(TreeSpecLib_derivs)
TreeSpecLib_derivs %>%
dplyr::select(taxon_code, everything()) %>%
dplyr::select(-sample_name:-`Columns..2.`) %>% #colnames()
rename(Classes = taxon_code) %>%
mutate(Classes = as.factor(Classes)) %>% as.data.frame()
TreeSpecLib_derivs <- TreeSpecLib_derivs %>%
dplyr::select(taxon_code, everything()) %>%
dplyr::select(-sample_name:-`Columns..2.`) %>% #colnames()
rename(Classes = taxon_code) %>%
mutate(Classes = as.factor(Classes)) %>%
as.data.frame()
TreeSpecLib_derivs
View(TreeSpecLib_derivs)
set.seed(123)
#rf_mod_ranger<- ranger::ranger(Classes ~ .,data = TreeSpecLib_derivs_cal, num.trees = 1000, local.importance = TRUE) # OOB prediction error:19.53 %
rf_mod_ranger <- ranger::ranger(Classes ~ ., data = TreeSpecLib_derivs, num.trees = 1000, local.importance = TRUE) # OOB prediction error:10.42 %
rf_mod_ranger
#rf_mod_randomforest<-randomForest(Classes ~ .,data = TreeSpecLib_derivs_cal, ntree=1000,importance=TRUE) # OOB prediction error 26.18%
rf_mod_randomforest <- randomForest(Classes ~ ., data = TreeSpecLib_derivs, ntree = 1000, importance = TRUE) # OOB prediction error 10.42 %
library(randomForest)
library(ranger)
#rf_mod_ranger<- ranger::ranger(Classes ~ .,data = TreeSpecLib_derivs_cal, num.trees = 1000, local.importance = TRUE) # OOB prediction error:19.53 %
rf_mod_ranger <- ranger::ranger(Classes ~ ., data = TreeSpecLib_derivs, num.trees = 1000, local.importance = TRUE) # OOB prediction error:10.42 %
rf_mod_ranger
#rf_mod_randomforest<-randomForest(Classes ~ .,data = TreeSpecLib_derivs_cal, ntree=1000,importance=TRUE) # OOB prediction error 26.18%
rf_mod_randomforest <- randomForest(Classes ~ ., data = TreeSpecLib_derivs, ntree = 1000, importance = TRUE) # OOB prediction error 10.42 %
#rf_mod_ranger<- ranger::ranger(Classes ~ .,data = TreeSpecLib_derivs_cal, num.trees = 1000, local.importance = TRUE) # OOB prediction error:19.53 %
rf_mod_ranger <- ranger::ranger(Classes ~ ., data = TreeSpecLib_derivs, num.trees = 1000, local.importance = TRUE) # OOB prediction error:10.42 %
rf_mod_ranger
#rf_mod_randomforest<-randomForest(Classes ~ .,data = TreeSpecLib_derivs_cal, ntree=1000,importance=TRUE) # OOB prediction error 26.18%
rf_mod_randomforest <- randomForest(Classes ~ ., data = TreeSpecLib_derivs, ntree = 1000, importance = TRUE) # OOB prediction error 10.42 %
# build models using 0.99 percent cutoff for correlated variables
# creates correlation matrix
CorelationMatrix <- cor(TreeSpecLib_derivs[-1])
# select most correlated variables
caret_findCorr <- findCorrelation(CorelationMatrix, cutoff = 0.99, names = T)
# remove correlated vars
predictor_df_reduced <- TreeSpecLib_derivs %>%
dplyr::select(-caret_findCorr)
library(caret)
# remove correlated vars
predictor_df_reduced <- TreeSpecLib_derivs %>%
dplyr::select(-caret_findCorr)
# rebuild models after intercorrelated vars are removed
rf_mod_randomforest_reduced <- randomForest(Classes ~ ., data = predictor_df_reduced, ntree = 1000, importance = TRUE) # OOB prediction error 23.28%
# saves confusion matrix rf
RandomForest_reduced_confusionmatrix <- rf_mod_randomforest_reduced$confusion %>%
as.data.frame()
write.csv(RandomForest_reduced_confusionmatrix, "Outputs/RandomForest_reduced_confusionmatrix_test.csv")
# saves confusion Matrix Ranger
rf_mod_ranger_reduced <- ranger(Classes ~ ., data = predictor_df_reduced,
num.trees = 1000,
local.importance = TRUE) # OOB prediction error:             17.97 %
rf_mod_ranger_IMP <- ranger(Classes ~ ., data = predictor_df_reduced,
num.trees = 1000,
importance = "impurity_corrected",
local.importance = TRUE) # OOB prediction error:             23.76 %
Ranger_reduced_confusionmatrix <- rf_mod_ranger_reduced$confusion.matrix %>%
as.data.frame.matrix()
Ranger_reduced_confusionmatrix
#Make models with all predictors for prediction
rf_mod_ranger_pred <- ranger::ranger(Classes ~ ., data = TreeSpecLib_derivs, num.trees = 1000) # OOB prediction error:10.42 %
rf_mod_ranger_pred
rf_mod_randomforest_pred <- randomForest(Classes ~ ., data = TreeSpecLib_derivs, ntree = 1000) # OOB prediction error 10.42 %
# saves the model with the lowest error
save(rf_mod_randomforest_pred, file = "Outputs/Best_Model_RandomForest.rda")
# saves the model with the lowest error
save(rf_mod_ranger_pred, file = "Outputs/Best_Model_Ranger.rda")
write.csv(Ranger_reduced_confusionmatrix,"Outputs/Ranger_reduced_confusionmatrix.csv")
write.csv(RandomForest_reduced_confusionmatrix, "Outputs/RandomForest_reduced_confusionmatrix.csv")
# creates a dataframe with all variables and their importance
ImportantVarsFrame <- enframe(rf_mod_ranger_IMP$variable.importance,
name = "predictor", value = "importance")
# Function Creates a plot of the 30 most important vars
ImportantVarsFrame25 <- ImportantVarsFrame[order(ImportantVarsFrame$importance, decreasing = TRUE), ][1:25, ]
# Lets R respect the order in dataframe
ImportantVarsFrame25$predictor <- factor(ImportantVarsFrame25$predictor,
levels = ImportantVarsFrame25$predictor
[order(ImportantVarsFrame25$importance)])
# Creates a plot of the 30 most important varibles
ImportantVarsFrame25 %>%
ggplot(aes(x  = predictor, y = importance)) +
theme_bw() +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("25 Most Important Varibles (Class_3)")
ggsave("Outputs/VarImp.png")
# Calls the function that will classify image
#source("Functions/LandCoverEstimator.R")
source("Functions/lecospectR.R")
# Calls the function that will classify image
source("Functions/LandCoverEstimator.R")
system.time(PredLayer <- LandCoverEstimator(
filename = "Original_data/Headwall/MSGC_TST_IMG",
out_file = "Output/test/",
#Classif_Model = "Output/E_003_Best_Model_RandomForest_86vars.rda",
Classif_Model = "Outputs/Best_Model_Ranger.rda",
datatype = "raster",
extension = FALSE))
system.time(PredLayer <- LandCoverEstimator(
filename = "Original_data/Headwall/MSGC_TST_IMG",
out_file = "Outputs/test/",
#Classif_Model = "Output/E_003_Best_Model_RandomForest_86vars.rda",
Classif_Model = "Outputs/Best_Model_Ranger.rda",
datatype = "raster",
extension = FALSE))
filename = "Original_data/Headwall/MSGC_TST_IMG"
# Reads in the Hyperspectral datacubes as a Rasterstack raster
Converted_Dcube <- raster::brick(filename)
install.packages("renv")
system.time(PredLayer <- LandCoverEstimator(
#filename = "Original_data/Headwall/MSGC_TST_IMG",
filename = "Original_data/Field_Spec/Maine/Howland_Scans",
out_file = "Outputs/test/",
#Classif_Model = "Output/E_003_Best_Model_RandomForest_86vars.rda",
Classif_Model = "Outputs/Best_Model_Ranger.rda",
datatype = "raster",
extension = FALSE))
