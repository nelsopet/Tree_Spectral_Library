{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!dir.exists(\"Functions/\")){\n",
    "    setwd(\"../\")\n",
    "    if(!dir.exists(\"Functions\")){\n",
    "        setwd(\"M:/MSGC_DATA/Tree_Spec_Lib/\")\n",
    "    }\n",
    "}\n",
    "source(\"Functions/lecospectR.R\", echo = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "log_model_results <- function(model_id, confusion_matrix, distribition, custom = NULL, logpath = \"./gs.log\"){\n",
    "    # append performance data to the logs for later comparison\n",
    "    sink(file = logpath, append = TRUE)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"---------------------- Model Data ---------------------\")\n",
    "    \n",
    "    print(paste0(\"Model Type: PLS-LDA (plsgenomics)\"))\n",
    "    print(paste0(\"Data Index: \",custom))\n",
    "    print(paste0(\"Model UUID: \", model_id))\n",
    "    print(\"---------------------- Confusion Matrix ---------------------\")\n",
    "    #print(confusion_matrix)\n",
    "    print(\"---------------------- Class Distribution ---------------------\")\n",
    "    #print(distribition)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    sink(NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add_model_to_manifest <- function(\n",
    "    model_id, \n",
    "    outlier = \"\", \n",
    "    preprocessing=\"\",\n",
    "    source=\"\", \n",
    "    weight = \"\",\n",
    "    n = \"\",\n",
    "    oob_error = \"\",\n",
    "    accuracy = \"\",\n",
    "    r2 = \"\",\n",
    "    chi2prob = \"\",\n",
    "    logpath=\"./gs_manifest.csv\"){\n",
    "    if(!file.exists(logpath)){\n",
    "        header <- \"source,outliers,preprocessing,weight,n,oob,accuracy,r2,rpd,model_id\"\n",
    "        write(header, file = logpath)\n",
    "    }\n",
    "\n",
    "    line <- paste(\n",
    "        source,\n",
    "        outlier,\n",
    "        preprocessing,\n",
    "        weight,\n",
    "        n,\n",
    "        oob_error,\n",
    "        accuracy,\n",
    "        r2,\n",
    "        chi2prob,\n",
    "        sep=\",\"\n",
    "    )\n",
    "    line <- paste0(line, \",\", model_id)\n",
    "\n",
    "    write(line, file=logpath, append = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_pls_lda <- function(\n",
    "    train_df, \n",
    "    train_labels,\n",
    "    test_df, \n",
    "    test_labels,\n",
    "    ncomp = 32,\n",
    "    outlier_fn = NULL,\n",
    "    preprocess_fn = NULL,\n",
    "    weight_fn = targets_to_weights,\n",
    "    model_id = uuid::UUIDgenerate(),\n",
    "    ignore_cols = NULL,\n",
    "    save_path = \"./mle/models\",\n",
    "    seed = NULL,\n",
    "    log_string = \"\"\n",
    "){\n",
    "\n",
    "    if(!is.null(seed)){\n",
    "        set.seed(seed)\n",
    "    }\n",
    "\n",
    "    x_train <- train_df %>% as.data.frame()\n",
    "    #x_test <- test_df %>% as.data.frame()\n",
    "    if(is.function(outlier_fn)){\n",
    "        x_train <- outlier_fn(x_train)\n",
    "    }\n",
    "    if(is.function(preprocess_fn)){\n",
    "        x_train <- preprocess_fn(x_train)\n",
    "        #x_test <- preprocess_fn(x_test)\n",
    "    }\n",
    "\n",
    "    sample_perm <- permute::shuffle(length(train_labels))\n",
    "    sample_index <- create_stratified_sample(\n",
    "        train_labels,\n",
    "        permutation = sample_perm,\n",
    "        samples_per_pft = 300\n",
    "    )\n",
    "    x_train <- x_train[sample_perm,][sample_index,]\n",
    "    train_labels <- train_labels[sample_perm][sample_index]\n",
    "\n",
    "    #if((\"Forb\" %in% levels(train_labels)) && !(\"Forb\"  %in% levels(test_labels))){\n",
    "        levels(test_labels) <- c(levels(test_labels), \"Forb\")\n",
    "    #    }\n",
    "    \n",
    "    model_s3_obj <- list(\n",
    "        x_train = x_train,\n",
    "        y_train = train_labels,\n",
    "        ncomp = ncomp,\n",
    "        nruncv = 0\n",
    "    )\n",
    "\n",
    "    class(model_s3_obj) <- \"pls_lda\"\n",
    "\n",
    "    save(\n",
    "        model_s3_obj,\n",
    "        file = file.path(save_path, paste0(model_id, \".rda\"))\n",
    "    )\n",
    "\n",
    "    # create predictions (ranger)\n",
    "    model_predictions <- predict(\n",
    "            model_s3_obj, \n",
    "            x_test\n",
    "        ) \n",
    "\n",
    "    print(model_predictions)\n",
    "\n",
    "\n",
    "    # generate the confusion matrix\n",
    "\n",
    "    confusion_matrix <- caret::confusionMatrix(\n",
    "        model_predictions %>% as.factor(),\n",
    "        test_labels,\n",
    "        mode = \"everything\"\n",
    "    )\n",
    "\n",
    "    log_model_results(\n",
    "            model_id = model_id,\n",
    "            confusion_matrix = confusion_matrix,\n",
    "            custom = log_string,\n",
    "            distribition = model_predictions %>% as.factor() %>% table(),\n",
    "            logpath = \"./gs_rf_n.log\")\n",
    "\n",
    "    return(\n",
    "        list(\n",
    "                model = model_s3_obj,\n",
    "                confusion = confusion_matrix %>% as.list()\n",
    "                )\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "apply_model.pls_lda <- function(x, model,  ...){\n",
    "    \n",
    "    if(\"x\" %in% colnames(x) && \"y\" %in% colnames(x)){\n",
    "        print(\"Spatial ifnormation detected, ignoring....\")\n",
    "        target_df <- subset(x, select=-c(x,y))\n",
    "        prediction_df <- predict.pls_lda(model, target_df) %>% as.data.frame()\n",
    "        prediction_df$x <- x$x\n",
    "        prediction_df$y <- x$y\n",
    "\n",
    "    } else {\n",
    "        prediction_df <- predict.pls_lda(model, x) %>% as.data.frame()\n",
    "    }\n",
    "\n",
    "    return(prediction_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write_pls_lda_model <- function(object, save_path, uuid = NULL){\n",
    "    model_id <- uuid\n",
    "    if(is.null(model_id)){\n",
    "        model_id <- uuid::UUIDgenerate()\n",
    "    }\n",
    "\n",
    "    save(x_train, x_train_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "predict.pls_lda <- function(pls_lda, x, ...){\n",
    "\n",
    "    predctions <- plsgenomics::pls.lda(\n",
    "        pls_lda$x_train,\n",
    "        pls_lda$y_train %>% as.numeric() + 1,\n",
    "        as.data.frame(x),\n",
    "        pls_lda$ncomp,\n",
    "        pls_lda$nruncv\n",
    "    )$predclass\n",
    "\n",
    "    predictions_df <- as.data.frame(as.numeric(predctions) - 1)\n",
    "    colnames(predictions_df) <- c(\"z\")\n",
    "    predictions_df$x <- rep(0,nrow(predictions_df))\n",
    "    predictions_df$y <- rep(0,nrow(predictions_df))\n",
    "\n",
    "\n",
    "    return(convert_fg1_int( predictions_df)$z %>% as.factor())\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "filter_target_subset <- function(df){\n",
    "\n",
    "    df_cols <- colnames(df) %>% as.character()\n",
    "    target_cols <- c(\n",
    "        \"Vogelmann\",\n",
    "        \"TVI\",\n",
    "        \"CRI4\",\n",
    "        \"Datt5\",\n",
    "        \"DWSI4\",\n",
    "        \"GDVI\",\n",
    "        \"MCARI\",\n",
    "        \"MTVI\",\n",
    "        \"NPCI\",\n",
    "        \"PARS\",\n",
    "        \"X417.593_5nm\",\n",
    "        \"X787.593_5nm\",\n",
    "        \"X892.593_5nm\"\n",
    "    )\n",
    "\n",
    "    used_cols <- intersect(df_cols, target_cols)\n",
    "    print(paste0(\"Filtering Data frame to the following columns: \", used_cols))\n",
    "    return(df[,used_cols])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "read_pls_lda_model <- function(pls_lda_obj){\n",
    "    x_train\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_model <- function(\n",
    "    train_df, \n",
    "    train_labels,\n",
    "    #test_df, \n",
    "    #test_labels,\n",
    "    ntree = 50,\n",
    "    max_depth = NULL,\n",
    "    mtry = NULL,\n",
    "    outlier_fn = NULL,\n",
    "    preprocess_fn = NULL,\n",
    "    weight_fn = NULL,\n",
    "    model_id = uuid::UUIDgenerate(),\n",
    "    ignore_cols = NULL,\n",
    "    seed = NULL,\n",
    "    log_string = \"\"\n",
    "){\n",
    "    if(!is.null(seed)){\n",
    "        set.seed(seed)\n",
    "    }\n",
    "\n",
    "    x_train <- train_df %>% as.data.frame()\n",
    "    #x_test <- test_df %>% as.data.frame()\n",
    "    if(is.function(outlier_fn)){\n",
    "        x_train <- outlier_fn(x_train)\n",
    "    }\n",
    "    if(is.function(preprocess_fn)){\n",
    "        x_train <- preprocess_fn(x_train)\n",
    "        #x_test <- preprocess_fn(x_test)\n",
    "    }\n",
    "\n",
    "    sample_perm <- permute::shuffle(length(train_labels))\n",
    "    #sample_index <- create_stratified_sample(\n",
    "    #    train_labels,\n",
    "    #    permutation = sample_perm,\n",
    "    #    samples_per_pft = 20\n",
    "    #)\n",
    "    #x_train <- x_train[sample_perm,][sample_index,]\n",
    "    #train_labels <- train_labels[sample_perm][sample_index]\n",
    "\n",
    "    model <- ranger::ranger(\n",
    "            num.trees = ntree,\n",
    "            mtry = mtry,\n",
    "            max.depth = max_depth,\n",
    "            #case.weights = weight_fn(train_labels),\n",
    "            classification = TRUE,\n",
    "            x=x_train,\n",
    "            y=train_labels\n",
    "        )\n",
    "\n",
    "    #if((\"Forb\" %in% levels(train_labels)) && !(\"Forb\"  %in% levels(test_labels))){\n",
    "    #        levels(test_labels) <- c(levels(test_labels), \"Forb\")\n",
    "    #        }\n",
    "\n",
    "    # create predictions (ranger)\n",
    "        #model_predictions <- predict(\n",
    "        #    model, \n",
    "        #    x_test\n",
    "        #)$prediction %>% as.factor()\n",
    "\n",
    "        # generate the confusion matrix\n",
    "\n",
    "        #confusion_matrix <- caret::confusionMatrix(\n",
    "        #    model_predictions, \n",
    "        #    test_labels,\n",
    "        #    mode = \"everything\"\n",
    "        #)\n",
    "\n",
    "        # generate an id to uniquely identify the model\n",
    "        #model_id <- uuid::UUIDgenerate()\n",
    "\n",
    "        # append performance data to the logs for later comparison\n",
    "        log_model_results(\n",
    "            model_id = model_id,\n",
    "            #confusion_matrix = confusion_matrix,\n",
    "            custom = log_string,\n",
    "            #distribition = model_predictions %>% as.factor() %>% table(),\n",
    "            logpath = \"./gs_pls_lda.log\")\n",
    "\n",
    "        # track what levels are associated with the UUID\n",
    "\n",
    "        # save the model using the model UUID\n",
    "        save(model, file = paste0(\"mle/models/gs/\", model_id, \".rda\"))\n",
    "        \n",
    "        return(\n",
    "            #list(\n",
    "                model #= model,\n",
    "                #confusion = confusion_matrix %>% as.list()\n",
    "                #)\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "base_paths <- c(\n",
    "    #\"img_raw_raw.csv\",\n",
    "    #\"corrected_and_img.csv\",\n",
    "    \"grd_raw_raw.csv\"#,\n",
    "    #\"bison_gulch_stratified.csv\",\n",
    "    #\"grd_raw_corrected.csv\",\n",
    "    #\"img_indices_only.csv\",# include veg indices\n",
    "    #\"grd_indices_only.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "calculate_posterior_weights <- function(validation_path =\"figures/merged_validation_s.csv\" ){\n",
    "\n",
    "    validation_df <- read.csv(validation_path, header = TRUE)\n",
    "    #print(head(validation_df))\n",
    "\n",
    "    total_observations <- sum(validation_df$validation_counts)\n",
    "    #print(total_observations)\n",
    "    weights <- (1/ validation_df$validation_prop)\n",
    "    #print(validation_df$validation_prop)\n",
    "\n",
    "    total_by_fg1 <- aggregate(\n",
    "        x = validation_df$validation_counts,\n",
    "        by = list(validation_df$key),\n",
    "        FUN = sum\n",
    "    )\n",
    "\n",
    "    fg1_weight_list <- list()\n",
    "\n",
    "    for( row_idx in seq(nrow(total_by_fg1))){\n",
    "        name <- total_by_fg1$Group.1[[row_idx]]\n",
    "        value <- total_by_fg1$x[[row_idx]]\n",
    "        fg1_weight_list[name] <- value\n",
    "    }\n",
    "    \n",
    "    return(fg1_weight_list)\n",
    "}\n",
    "\n",
    "get_posterior_weights_from_targets <- function(target_factor, posterior_weight = calculate_posterior_weights()){\n",
    "    unbiased_weights <- targets_to_weights(target_factor)\n",
    "\n",
    "    target_name_char <- target_factor %>% as.character()\n",
    "\n",
    "    output_weights <- seq_along(target_factor)\n",
    "\n",
    "    for(i in seq_along(target_factor)){\n",
    "        if(posterior_weight[[target_name_char[[i]]]] > 0){\n",
    "            fg1_weight <- 1 / posterior_weight[[target_name_char[[i]]]]\n",
    "        } else {\n",
    "            fg1_weight <- 0\n",
    "        }\n",
    "        output_weights[[i]] <- unbiased_weights[[i]] * fg1_weight\n",
    "    }\n",
    "\n",
    "    return(output_weights)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "\n",
    "Peter\n",
    "* Increasing number of trees will improve the accuracy/validation mismatch\n",
    "* bias in \n",
    "\n",
    "Ken\n",
    "* decreasing the number of the trees will decrease the impact of the posterior weighting on chi-squared statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "outlier_functions <- list(\n",
    "    #clip = load_model(\"./mle/clip_transform.rda\"),\n",
    "    no_treatment = function(x, ignore_cols = NULL){return(x)}# no transform\n",
    ")\n",
    "\n",
    "outlier_treatments <- c(\n",
    "    \"no_treatment\"#,\n",
    "    #\"clip\"\n",
    ")\n",
    "\n",
    "preprocess_functions <- list(\n",
    "    no_treatment = function(x, ignore_cols = NULL){return(x)},# no transform\n",
    "    min_max = columnwise_min_max_scale,\n",
    "    robust = columnwise_robust_scale,\n",
    "    standard = standardize_df\n",
    ")\n",
    "\n",
    "weight_functions <- list(\n",
    "    posterior = get_posterior_weights_from_targets,\n",
    "    balanced = targets_to_weights,\n",
    "    no_treatment = function(x){return(NULL)}# No weights\n",
    ")\n",
    "weight_treatments <- c(\n",
    "    \"no_treatment\"#,\n",
    "    #\"balanced\"#,\n",
    "    #\"posterior\"\n",
    ")\n",
    "\n",
    "preprocessing_treatments <- c(\n",
    "    \"no_treatment\"#,\n",
    "    #\"min_max\",\n",
    "    #\"standard\",\n",
    "    #\"robust\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "num_components <- c(\n",
    "    #1,\n",
    "    #2,\n",
    "    ##4,6,\n",
    "    #8,#\n",
    "    #10,\n",
    "    #12,#14,\n",
    "    #16,#18,20,24,\n",
    "    #32,#50,\n",
    "    #64,#100,\n",
    "    #128,\n",
    "    #256,\n",
    "    #512#,1024\n",
    "    500,\n",
    "    1000,\n",
    "    5000\n",
    ")\n",
    "\n",
    "depth_control <- c(\n",
    "    #10,20, \n",
    "    45\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "to_fg0 <- function(target_factor){\n",
    "    return(\n",
    "        change_aggregation(\n",
    "            target_factor,\n",
    "            0,\n",
    "            rjson::fromJSON(file=\"./assets/pft_adj_list.json\")\n",
    "        )\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#test_data <- subset(read.csv(\"Data/gs/x_test/img_raw_raw.csv\"), select = -c(X))\n",
    "#test_labels <- read.csv(\"Data/gs/y_test/img_raw_raw.csv\")$x %>% to_fg0() %>% as.factor()\n",
    "#train_labels <- read.csv(\"Data/gs/y_train/img_raw_raw.csv\")$x %>% as.factor()\n",
    "train_labels <- read.csv(\"Data/gs/y_train/grd_raw_raw.csv\")$x %>% as.factor()\n",
    "\n",
    "#manifest_path <- \"./gs_manifest_reduced_val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>abibal</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acepen</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acerub</li><li>acesac</li><li>acesac</li><li>acesac</li><li>acesac</li><li>acesac</li><li>acesac</li><li>acesac</li><li>acesac</li><li>acesac</li><li>acesac</li><li>acesac</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>alninc</li><li>betall</li><li>betall</li><li>betall</li><li>⋯</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popbal</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>popgra</li><li>poptre</li><li>poptre</li><li>poptre</li><li>poptre</li><li>poptre</li><li>poptre</li><li>poptre</li><li>poptre</li><li>poptre</li><li>poptre</li><li>poptre</li><li>prupen</li><li>prupen</li><li>prupen</li><li>prupen</li><li>prupen</li><li>prupen</li><li>prupen</li><li>prupen</li><li>prupen</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>querub</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>rhutyp</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>thuocc</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li><li>tsucan</li></ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'abibal'</li><li>'acepen'</li><li>'acerub'</li><li>'acesac'</li><li>'alninc'</li><li>'betall'</li><li>'betpap'</li><li>'betpop'</li><li>'faggra'</li><li>'fraame'</li><li>'larlar'</li><li>'picgla'</li><li>'picrub'</li><li>'pinstr'</li><li>'popbal'</li><li>'popgra'</li><li>'poptre'</li><li>'prupen'</li><li>'querub'</li><li>'rhutyp'</li><li>'thuocc'</li><li>'tsucan'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item abibal\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acepen\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acerub\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item acesac\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item alninc\n",
       "\\item betall\n",
       "\\item betall\n",
       "\\item betall\n",
       "\\item ⋯\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popbal\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item popgra\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item poptre\n",
       "\\item prupen\n",
       "\\item prupen\n",
       "\\item prupen\n",
       "\\item prupen\n",
       "\\item prupen\n",
       "\\item prupen\n",
       "\\item prupen\n",
       "\\item prupen\n",
       "\\item prupen\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item querub\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item rhutyp\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item thuocc\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\item tsucan\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'abibal'\n",
       "\\item 'acepen'\n",
       "\\item 'acerub'\n",
       "\\item 'acesac'\n",
       "\\item 'alninc'\n",
       "\\item 'betall'\n",
       "\\item 'betpap'\n",
       "\\item 'betpop'\n",
       "\\item 'faggra'\n",
       "\\item 'fraame'\n",
       "\\item 'larlar'\n",
       "\\item 'picgla'\n",
       "\\item 'picrub'\n",
       "\\item 'pinstr'\n",
       "\\item 'popbal'\n",
       "\\item 'popgra'\n",
       "\\item 'poptre'\n",
       "\\item 'prupen'\n",
       "\\item 'querub'\n",
       "\\item 'rhutyp'\n",
       "\\item 'thuocc'\n",
       "\\item 'tsucan'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. abibal\n",
       "2. abibal\n",
       "3. abibal\n",
       "4. abibal\n",
       "5. abibal\n",
       "6. abibal\n",
       "7. abibal\n",
       "8. abibal\n",
       "9. abibal\n",
       "10. abibal\n",
       "11. abibal\n",
       "12. abibal\n",
       "13. abibal\n",
       "14. abibal\n",
       "15. abibal\n",
       "16. abibal\n",
       "17. abibal\n",
       "18. abibal\n",
       "19. abibal\n",
       "20. abibal\n",
       "21. abibal\n",
       "22. abibal\n",
       "23. abibal\n",
       "24. abibal\n",
       "25. abibal\n",
       "26. abibal\n",
       "27. abibal\n",
       "28. abibal\n",
       "29. abibal\n",
       "30. abibal\n",
       "31. abibal\n",
       "32. abibal\n",
       "33. abibal\n",
       "34. abibal\n",
       "35. abibal\n",
       "36. abibal\n",
       "37. abibal\n",
       "38. abibal\n",
       "39. abibal\n",
       "40. abibal\n",
       "41. abibal\n",
       "42. abibal\n",
       "43. abibal\n",
       "44. abibal\n",
       "45. abibal\n",
       "46. abibal\n",
       "47. abibal\n",
       "48. abibal\n",
       "49. abibal\n",
       "50. abibal\n",
       "51. abibal\n",
       "52. abibal\n",
       "53. abibal\n",
       "54. abibal\n",
       "55. abibal\n",
       "56. abibal\n",
       "57. abibal\n",
       "58. abibal\n",
       "59. abibal\n",
       "60. abibal\n",
       "61. abibal\n",
       "62. abibal\n",
       "63. abibal\n",
       "64. abibal\n",
       "65. abibal\n",
       "66. abibal\n",
       "67. abibal\n",
       "68. abibal\n",
       "69. acepen\n",
       "70. acepen\n",
       "71. acepen\n",
       "72. acepen\n",
       "73. acepen\n",
       "74. acepen\n",
       "75. acepen\n",
       "76. acepen\n",
       "77. acepen\n",
       "78. acepen\n",
       "79. acepen\n",
       "80. acepen\n",
       "81. acepen\n",
       "82. acepen\n",
       "83. acepen\n",
       "84. acepen\n",
       "85. acepen\n",
       "86. acepen\n",
       "87. acepen\n",
       "88. acepen\n",
       "89. acepen\n",
       "90. acepen\n",
       "91. acepen\n",
       "92. acepen\n",
       "93. acepen\n",
       "94. acepen\n",
       "95. acepen\n",
       "96. acepen\n",
       "97. acepen\n",
       "98. acepen\n",
       "99. acepen\n",
       "100. acepen\n",
       "101. acepen\n",
       "102. acepen\n",
       "103. acepen\n",
       "104. acepen\n",
       "105. acepen\n",
       "106. acerub\n",
       "107. acerub\n",
       "108. acerub\n",
       "109. acerub\n",
       "110. acerub\n",
       "111. acerub\n",
       "112. acerub\n",
       "113. acerub\n",
       "114. acerub\n",
       "115. acerub\n",
       "116. acerub\n",
       "117. acerub\n",
       "118. acerub\n",
       "119. acerub\n",
       "120. acerub\n",
       "121. acerub\n",
       "122. acerub\n",
       "123. acerub\n",
       "124. acerub\n",
       "125. acerub\n",
       "126. acerub\n",
       "127. acerub\n",
       "128. acerub\n",
       "129. acerub\n",
       "130. acerub\n",
       "131. acerub\n",
       "132. acerub\n",
       "133. acerub\n",
       "134. acerub\n",
       "135. acerub\n",
       "136. acerub\n",
       "137. acerub\n",
       "138. acerub\n",
       "139. acerub\n",
       "140. acerub\n",
       "141. acerub\n",
       "142. acerub\n",
       "143. acerub\n",
       "144. acerub\n",
       "145. acerub\n",
       "146. acerub\n",
       "147. acerub\n",
       "148. acerub\n",
       "149. acerub\n",
       "150. acerub\n",
       "151. acerub\n",
       "152. acerub\n",
       "153. acerub\n",
       "154. acerub\n",
       "155. acerub\n",
       "156. acerub\n",
       "157. acerub\n",
       "158. acerub\n",
       "159. acerub\n",
       "160. acesac\n",
       "161. acesac\n",
       "162. acesac\n",
       "163. acesac\n",
       "164. acesac\n",
       "165. acesac\n",
       "166. acesac\n",
       "167. acesac\n",
       "168. acesac\n",
       "169. acesac\n",
       "170. acesac\n",
       "171. alninc\n",
       "172. alninc\n",
       "173. alninc\n",
       "174. alninc\n",
       "175. alninc\n",
       "176. alninc\n",
       "177. alninc\n",
       "178. alninc\n",
       "179. alninc\n",
       "180. alninc\n",
       "181. alninc\n",
       "182. alninc\n",
       "183. alninc\n",
       "184. alninc\n",
       "185. alninc\n",
       "186. alninc\n",
       "187. alninc\n",
       "188. alninc\n",
       "189. alninc\n",
       "190. alninc\n",
       "191. alninc\n",
       "192. alninc\n",
       "193. alninc\n",
       "194. alninc\n",
       "195. alninc\n",
       "196. alninc\n",
       "197. alninc\n",
       "198. betall\n",
       "199. betall\n",
       "200. betall\n",
       "201. ⋯\n",
       "202. popbal\n",
       "203. popbal\n",
       "204. popbal\n",
       "205. popbal\n",
       "206. popbal\n",
       "207. popbal\n",
       "208. popbal\n",
       "209. popbal\n",
       "210. popbal\n",
       "211. popbal\n",
       "212. popbal\n",
       "213. popbal\n",
       "214. popbal\n",
       "215. popbal\n",
       "216. popbal\n",
       "217. popbal\n",
       "218. popbal\n",
       "219. popbal\n",
       "220. popbal\n",
       "221. popbal\n",
       "222. popbal\n",
       "223. popbal\n",
       "224. popbal\n",
       "225. popbal\n",
       "226. popbal\n",
       "227. popbal\n",
       "228. popbal\n",
       "229. popbal\n",
       "230. popbal\n",
       "231. popbal\n",
       "232. popbal\n",
       "233. popbal\n",
       "234. popbal\n",
       "235. popbal\n",
       "236. popbal\n",
       "237. popbal\n",
       "238. popbal\n",
       "239. popbal\n",
       "240. popbal\n",
       "241. popgra\n",
       "242. popgra\n",
       "243. popgra\n",
       "244. popgra\n",
       "245. popgra\n",
       "246. popgra\n",
       "247. popgra\n",
       "248. popgra\n",
       "249. popgra\n",
       "250. popgra\n",
       "251. popgra\n",
       "252. popgra\n",
       "253. popgra\n",
       "254. popgra\n",
       "255. popgra\n",
       "256. poptre\n",
       "257. poptre\n",
       "258. poptre\n",
       "259. poptre\n",
       "260. poptre\n",
       "261. poptre\n",
       "262. poptre\n",
       "263. poptre\n",
       "264. poptre\n",
       "265. poptre\n",
       "266. poptre\n",
       "267. prupen\n",
       "268. prupen\n",
       "269. prupen\n",
       "270. prupen\n",
       "271. prupen\n",
       "272. prupen\n",
       "273. prupen\n",
       "274. prupen\n",
       "275. prupen\n",
       "276. querub\n",
       "277. querub\n",
       "278. querub\n",
       "279. querub\n",
       "280. querub\n",
       "281. querub\n",
       "282. querub\n",
       "283. querub\n",
       "284. querub\n",
       "285. querub\n",
       "286. querub\n",
       "287. querub\n",
       "288. querub\n",
       "289. querub\n",
       "290. querub\n",
       "291. rhutyp\n",
       "292. rhutyp\n",
       "293. rhutyp\n",
       "294. rhutyp\n",
       "295. rhutyp\n",
       "296. rhutyp\n",
       "297. rhutyp\n",
       "298. rhutyp\n",
       "299. rhutyp\n",
       "300. rhutyp\n",
       "301. rhutyp\n",
       "302. rhutyp\n",
       "303. rhutyp\n",
       "304. rhutyp\n",
       "305. rhutyp\n",
       "306. rhutyp\n",
       "307. rhutyp\n",
       "308. rhutyp\n",
       "309. rhutyp\n",
       "310. rhutyp\n",
       "311. rhutyp\n",
       "312. rhutyp\n",
       "313. rhutyp\n",
       "314. rhutyp\n",
       "315. rhutyp\n",
       "316. rhutyp\n",
       "317. rhutyp\n",
       "318. rhutyp\n",
       "319. rhutyp\n",
       "320. rhutyp\n",
       "321. rhutyp\n",
       "322. rhutyp\n",
       "323. rhutyp\n",
       "324. rhutyp\n",
       "325. rhutyp\n",
       "326. thuocc\n",
       "327. thuocc\n",
       "328. thuocc\n",
       "329. thuocc\n",
       "330. thuocc\n",
       "331. thuocc\n",
       "332. thuocc\n",
       "333. thuocc\n",
       "334. thuocc\n",
       "335. thuocc\n",
       "336. thuocc\n",
       "337. thuocc\n",
       "338. thuocc\n",
       "339. thuocc\n",
       "340. thuocc\n",
       "341. thuocc\n",
       "342. thuocc\n",
       "343. thuocc\n",
       "344. thuocc\n",
       "345. thuocc\n",
       "346. thuocc\n",
       "347. thuocc\n",
       "348. thuocc\n",
       "349. thuocc\n",
       "350. tsucan\n",
       "351. tsucan\n",
       "352. tsucan\n",
       "353. tsucan\n",
       "354. tsucan\n",
       "355. tsucan\n",
       "356. tsucan\n",
       "357. tsucan\n",
       "358. tsucan\n",
       "359. tsucan\n",
       "360. tsucan\n",
       "361. tsucan\n",
       "362. tsucan\n",
       "363. tsucan\n",
       "364. tsucan\n",
       "365. tsucan\n",
       "366. tsucan\n",
       "367. tsucan\n",
       "368. tsucan\n",
       "369. tsucan\n",
       "370. tsucan\n",
       "371. tsucan\n",
       "372. tsucan\n",
       "373. tsucan\n",
       "374. tsucan\n",
       "375. tsucan\n",
       "376. tsucan\n",
       "377. tsucan\n",
       "378. tsucan\n",
       "379. tsucan\n",
       "380. tsucan\n",
       "381. tsucan\n",
       "382. tsucan\n",
       "383. tsucan\n",
       "384. tsucan\n",
       "385. tsucan\n",
       "386. tsucan\n",
       "387. tsucan\n",
       "388. tsucan\n",
       "389. tsucan\n",
       "390. tsucan\n",
       "391. tsucan\n",
       "392. tsucan\n",
       "393. tsucan\n",
       "394. tsucan\n",
       "395. tsucan\n",
       "396. tsucan\n",
       "397. tsucan\n",
       "398. tsucan\n",
       "399. tsucan\n",
       "400. tsucan\n",
       "401. tsucan\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'abibal'\n",
       "2. 'acepen'\n",
       "3. 'acerub'\n",
       "4. 'acesac'\n",
       "5. 'alninc'\n",
       "6. 'betall'\n",
       "7. 'betpap'\n",
       "8. 'betpop'\n",
       "9. 'faggra'\n",
       "10. 'fraame'\n",
       "11. 'larlar'\n",
       "12. 'picgla'\n",
       "13. 'picrub'\n",
       "14. 'pinstr'\n",
       "15. 'popbal'\n",
       "16. 'popgra'\n",
       "17. 'poptre'\n",
       "18. 'prupen'\n",
       "19. 'querub'\n",
       "20. 'rhutyp'\n",
       "21. 'thuocc'\n",
       "22. 'tsucan'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] abibal abibal abibal abibal abibal abibal abibal abibal abibal abibal\n",
       " [11] abibal abibal abibal abibal abibal abibal abibal abibal abibal abibal\n",
       " [21] abibal abibal abibal abibal abibal abibal abibal abibal abibal abibal\n",
       " [31] abibal abibal abibal abibal abibal abibal abibal abibal abibal abibal\n",
       " [41] abibal abibal abibal abibal abibal abibal abibal abibal abibal abibal\n",
       " [51] abibal abibal abibal abibal abibal abibal abibal abibal abibal abibal\n",
       " [61] abibal abibal abibal abibal abibal abibal abibal abibal acepen acepen\n",
       " [71] acepen acepen acepen acepen acepen acepen acepen acepen acepen acepen\n",
       " [81] acepen acepen acepen acepen acepen acepen acepen acepen acepen acepen\n",
       " [91] acepen acepen acepen acepen acepen acepen acepen acepen acepen acepen\n",
       "[101] acepen acepen acepen acepen acepen acerub acerub acerub acerub acerub\n",
       "[111] acerub acerub acerub acerub acerub acerub acerub acerub acerub acerub\n",
       "[121] acerub acerub acerub acerub acerub acerub acerub acerub acerub acerub\n",
       "[131] acerub acerub acerub acerub acerub acerub acerub acerub acerub acerub\n",
       "[141] acerub acerub acerub acerub acerub acerub acerub acerub acerub acerub\n",
       "[151] acerub acerub acerub acerub acerub acerub acerub acerub acerub acesac\n",
       "[161] acesac acesac acesac acesac acesac acesac acesac acesac acesac acesac\n",
       "[171] alninc alninc alninc alninc alninc alninc alninc alninc alninc alninc\n",
       "[181] alninc alninc alninc alninc alninc alninc alninc alninc alninc alninc\n",
       "[191] alninc alninc alninc alninc alninc alninc alninc betall betall betall\n",
       "[201] betall betall betall betall betall betall betall betall betall betall\n",
       "[211] betall betall betall betall betall betall betall betall betall betall\n",
       "[221] betall betall betall betall betall betall betall betall betall betall\n",
       "[231] betall betall betall betall betall betpap betpap betpap betpap betpap\n",
       "[241] betpap betpap betpap betpap betpap betpap betpap betpap betpap betpap\n",
       "[251] betpap betpap betpap betpap betpap betpap betpap betpap betpap betpop\n",
       "[261] betpop betpop betpop betpop betpop betpop betpop betpop betpop betpop\n",
       "[271] betpop betpop betpop betpop betpop betpop betpop betpop betpop betpop\n",
       "[281] betpop betpop betpop betpop betpop betpop betpop betpop betpop betpop\n",
       "[291] betpop betpop betpop faggra faggra faggra faggra faggra faggra faggra\n",
       "[301] faggra faggra faggra faggra faggra faggra faggra faggra faggra faggra\n",
       "[311] faggra faggra faggra faggra faggra faggra faggra faggra faggra faggra\n",
       "[321] faggra faggra faggra faggra faggra faggra faggra faggra faggra faggra\n",
       "[331] faggra faggra faggra faggra faggra faggra faggra faggra faggra faggra\n",
       "[341] fraame fraame fraame fraame fraame fraame fraame fraame fraame fraame\n",
       "[351] fraame fraame fraame fraame fraame fraame fraame fraame fraame fraame\n",
       "[361] fraame fraame fraame fraame fraame fraame larlar larlar larlar larlar\n",
       "[371] larlar larlar larlar larlar larlar larlar larlar larlar larlar larlar\n",
       "[381] larlar larlar larlar larlar larlar larlar picgla picgla picgla picgla\n",
       "[391] picgla picgla picgla picgla picgla picgla picgla picgla picgla picgla\n",
       "[401] picgla picgla picgla picgla picgla picgla picgla picgla picgla picgla\n",
       "[411] picgla picgla picgla picgla picgla picgla picgla picgla picgla picgla\n",
       "[421] picgla picgla picgla picgla picrub picrub picrub picrub picrub picrub\n",
       "[431] picrub picrub picrub picrub picrub picrub picrub picrub picrub picrub\n",
       "[441] picrub picrub picrub picrub picrub picrub picrub picrub picrub picrub\n",
       "[451] picrub picrub picrub picrub picrub picrub picrub picrub picrub picrub\n",
       "[461] picrub picrub picrub picrub picrub picrub picrub picrub picrub picrub\n",
       "[471] picrub picrub picrub picrub picrub picrub picrub picrub picrub picrub\n",
       "[481] picrub picrub picrub picrub picrub picrub pinstr pinstr pinstr pinstr\n",
       "[491] pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr\n",
       "[501] pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr\n",
       "[511] pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr\n",
       "[521] pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr\n",
       "[531] pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr pinstr popbal\n",
       "[541] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[551] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[561] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[571] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[581] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[591] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[601] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[611] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[621] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[631] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[641] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[651] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[661] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[671] popbal popbal popbal popbal popbal popbal popbal popbal popbal popbal\n",
       "[681] popbal popbal popbal popbal popgra popgra popgra popgra popgra popgra\n",
       "[691] popgra popgra popgra popgra popgra popgra popgra popgra popgra poptre\n",
       "[701] poptre poptre poptre poptre poptre poptre poptre poptre poptre poptre\n",
       "[711] prupen prupen prupen prupen prupen prupen prupen prupen prupen querub\n",
       "[721] querub querub querub querub querub querub querub querub querub querub\n",
       "[731] querub querub querub querub rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp\n",
       "[741] rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp\n",
       "[751] rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp\n",
       "[761] rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp rhutyp thuocc\n",
       "[771] thuocc thuocc thuocc thuocc thuocc thuocc thuocc thuocc thuocc thuocc\n",
       "[781] thuocc thuocc thuocc thuocc thuocc thuocc thuocc thuocc thuocc thuocc\n",
       "[791] thuocc thuocc thuocc tsucan tsucan tsucan tsucan tsucan tsucan tsucan\n",
       "[801] tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan\n",
       "[811] tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan\n",
       "[821] tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan\n",
       "[831] tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan tsucan\n",
       "[841] tsucan tsucan tsucan tsucan tsucan\n",
       "22 Levels: abibal acepen acerub acesac alninc betall betpap betpop ... tsucan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rf_model_results <- train_model(\n",
    "    train_data,\n",
    "    train_labels, \n",
    "    #test_data,\n",
    "    #test_labels,\n",
    "    ntree = 100,\n",
    "    max_depth = NULL,#d,\n",
    "    #outlier_fn = outlier_functions[[o_treatment]],\n",
    "    #preprocess_fn = preprocess_functions[[p_treatment]],\n",
    "    #weight_fn = weight_functions[[w_treatment]],\n",
    "    #model_id = model_id,\n",
    "    seed=61718#,\n",
    "    #log_string = paste(n, filepath, o_treatment, p_treatment, w_treatment)\n",
    ")\n",
    "#print(rf_model_results)\n",
    "rf_model <- rf_model_results$model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for(filepath in base_paths){\n",
    "    train_data <- subset(read.csv(paste0(\"Data/gs/x_train/\", filepath)), select = -c(X))\n",
    "    labels <- read.csv(paste0(\"Data/gs/y_train/\", filepath))$x  %>% as.factor() #to_fg0() \n",
    "    for(o_treatment in outlier_treatments){\n",
    "        for(p_treatment in preprocessing_treatments){\n",
    "            for(w_treatment in weight_treatments){\n",
    "                for(n in num_components){\n",
    "#                    for(d in depth_control){\n",
    "\n",
    "                model_id <- uuid::UUIDgenerate()\n",
    "                save_path <- paste0(\"mle/experiments/gs/\", model_id, \"/\")\n",
    "                if(!dir.exists(save_path)){\n",
    "                    dir.create(save_path)\n",
    "                }\n",
    "\n",
    "                rf_model_results <- train_model(\n",
    "                    #filter_df_bands(train_data), \n",
    "                    train_data,\n",
    "                    labels, \n",
    "                    #test_data,\n",
    "                    #test_labels,\n",
    "                    ntree = n,\n",
    "                    max_depth = NULL,#d,\n",
    "                    outlier_fn = outlier_functions[[o_treatment]],\n",
    "                    preprocess_fn = preprocess_functions[[p_treatment]],\n",
    "                    weight_fn = weight_functions[[w_treatment]],\n",
    "                    model_id = model_id,\n",
    "                    seed=61718,\n",
    "                    log_string = paste(n, filepath, o_treatment, p_treatment, w_treatment)\n",
    "                )\n",
    "                #print(rf_model_results)\n",
    "\n",
    "                rf_model <- rf_model_results$model\n",
    "                #acc <- as.list(rf_model_results$confusion$overall)$Accuracy\n",
    "                #print(acc)\n",
    "\n",
    "                #if(acc > 0.6){\n",
    "\n",
    "\n",
    "                #results <- validate_model(\n",
    "                #    rf_model, \n",
    "                #    save_path, \n",
    "                #    outlier_processing = outlier_functions[[o_treatment]],\n",
    "                #    transform_type = preprocess_functions[[p_treatment]],\n",
    "                #    pft_aggregation = 0\n",
    "                #)\n",
    "\n",
    "                #aggregated_results <- aggregate_results(save_path)\n",
    "\n",
    "                # calculate validation statistics\n",
    "                #chi2 <- calculate_chi_squared_probability(aggregated_results)\n",
    "                #r2 <- calculate_validation_r2(aggregated_results)\n",
    "                #rpd <- calculate_rpd(aggregated_results)\n",
    "#\n",
    "                #add_model_to_manifest(\n",
    "                #    model_id = model_id,\n",
    "                #    outlier = o_treatment,\n",
    "                #    preprocessing = p_treatment,\n",
    "                #    source = filepath,\n",
    "                #    weight = w_treatment,\n",
    "                #    n = n,\n",
    "                #    oob_error = rf_model$prediction.error,\n",
    "                #    accuracy = acc,\n",
    "                #    r2 = r2,\n",
    "                #    chi2prob = rpd,\n",
    "                #    logpath=manifest_path\n",
    "                #)\n",
    "#\n",
    "                #plot_by_pft(\n",
    "                #    aggregated_results,\n",
    "                #    save_path = paste0(save_path, \"aggregate.html\"),\n",
    "                #    open = FALSE,\n",
    "                #    image_path = NULL,\n",
    "                #    aggregation=0\n",
    "                #)\n",
    "            ##\n",
    "                #write_validation_table(\n",
    "                #    aggregated_results,\n",
    "                #    save_path = paste0(save_path, \"table.html\"),\n",
    "                #    open = FALSE\n",
    "                #)\n",
    "                #} else {\n",
    "                #    add_model_to_manifest(\n",
    "                #        model_id = model_id,\n",
    "                #        outlier = o_treatment,\n",
    "                #        preprocessing = p_treatment,\n",
    "                #        source = filepath,\n",
    "                #        weight = w_treatment,\n",
    "                #        n = n,\n",
    "                #        oob_error = rf_model$prediction.error,\n",
    "                #        accuracy = acc,\n",
    "                #        r2 = \"Skipped\",\n",
    "                #        chi2prob = \"Skipped\",\n",
    "                #        logpath=manifest_path\n",
    "                #    )\n",
    "\n",
    "                #}\n",
    "                   # }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        predicted\n",
       "true     abibal acepen acerub acesac alninc betall betpap betpop faggra fraame\n",
       "  abibal     34      0      1      0      1      0      0      2      0      0\n",
       "  acepen      0     29      1      0      4      1      0      0      1      0\n",
       "  acerub      0      0     37      0      0      3      1      0      5      1\n",
       "  acesac      0      0      0      4      0      2      3      0      1      0\n",
       "  alninc      0      5      2      0     14      0      0      0      1      1\n",
       "  betall      0      2      2      3      0     24      0      0      0      2\n",
       "  betpap      0      0      2      1      0      1     12      2      2      0\n",
       "  betpop      0      0      2      0      0      1      4     15      5      0\n",
       "  faggra      0      2      3      0      0      0      0      2     37      1\n",
       "  fraame      0      0      0      0      0      1      0      2      1     20\n",
       "  larlar      4      0      0      0      0      0      0      0      0      0\n",
       "  picgla      3      0      0      0      0      0      0      0      0      0\n",
       "  picrub      6      0      0      0      0      0      0      0      0      0\n",
       "  pinstr      3      0      0      0      0      0      0      0      0      0\n",
       "  popbal      1      0      1      1      3      1      1      0      0      0\n",
       "  popgra      0      0      1      0      0      0      0      0      1      0\n",
       "  poptre      0      0      1      0      0      1      1      0      0      0\n",
       "  prupen      0      2      1      0      0      0      0      0      0      0\n",
       "  querub      0      2      0      0      0      0      0      0      1      0\n",
       "  rhutyp      0      1      1      0      0      0      1      1      0      0\n",
       "  thuocc      2      0      0      0      0      1      0      0      0      0\n",
       "  tsucan      5      0      3      0      0      0      0      0      0      0\n",
       "        predicted\n",
       "true     larlar picgla picrub pinstr popbal popgra poptre prupen querub rhutyp\n",
       "  abibal      1      6     12      2      3      0      1      0      0      2\n",
       "  acepen      0      0      0      0      1      0      0      0      0      0\n",
       "  acerub      0      0      0      0      5      0      0      0      0      2\n",
       "  acesac      0      0      0      0      0      0      1      0      0      0\n",
       "  alninc      0      0      0      0      2      0      0      0      0      2\n",
       "  betall      0      0      0      0      5      0      0      0      0      0\n",
       "  betpap      0      0      0      0      2      0      1      0      0      1\n",
       "  betpop      0      0      0      0      6      0      0      0      0      1\n",
       "  faggra      0      0      0      0      0      0      0      0      0      2\n",
       "  fraame      0      0      0      0      2      0      0      0      0      0\n",
       "  larlar      6      3      3      1      0      0      0      0      0      0\n",
       "  picgla      0     27      4      0      0      0      0      0      0      0\n",
       "  picrub      0      3     39      6      0      2      1      0      0      0\n",
       "  pinstr      0      0      3     41      1      0      0      0      0      0\n",
       "  popbal      0      1      0      1    135      0      0      0      0      0\n",
       "  popgra      0      0      0      0      0     12      0      0      1      0\n",
       "  poptre      0      0      0      0      1      0      6      0      0      1\n",
       "  prupen      0      0      0      0      0      0      0      6      0      0\n",
       "  querub      0      0      0      0      0      0      0      0     12      0\n",
       "  rhutyp      0      0      0      0      0      0      0      0      0     31\n",
       "  thuocc      1      0      5      2      1      0      0      0      0      0\n",
       "  tsucan      2      3      5      5      6      0      0      0      0      0\n",
       "        predicted\n",
       "true     thuocc tsucan\n",
       "  abibal      1      2\n",
       "  acepen      0      0\n",
       "  acerub      0      0\n",
       "  acesac      0      0\n",
       "  alninc      0      0\n",
       "  betall      0      0\n",
       "  betpap      0      0\n",
       "  betpop      0      0\n",
       "  faggra      0      0\n",
       "  fraame      0      0\n",
       "  larlar      0      3\n",
       "  picgla      0      4\n",
       "  picrub      0      5\n",
       "  pinstr      1      4\n",
       "  popbal      0      0\n",
       "  popgra      0      0\n",
       "  poptre      0      0\n",
       "  prupen      0      0\n",
       "  querub      0      0\n",
       "  rhutyp      0      0\n",
       "  thuocc      8      4\n",
       "  tsucan      1     22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#list.files(\"mle/models/gs\")\n",
    "mod<-load_model(\"mle/models/gs/62f07a30-dd1e-4621-8752-abafe2803378.rda\")\n",
    "mod$confusion.matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
